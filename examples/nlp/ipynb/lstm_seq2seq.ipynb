{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafikSameh/Neural_Machine_Translation/blob/main/examples/nlp/ipynb/lstm_seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "v6tTpc5rT2VG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import os\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MzMrlfZfT2VI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MB5CUGk7T2VI"
      },
      "outputs": [],
      "source": [
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 500 # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 6000  # Number of samples to train on.\n",
        "# Path to the data txt file on disk.\n",
        "data_path = \"ara.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "C0NVjhakT2VI",
        "outputId": "fb4c1258-a245-49e2-f185-7a06d0344b6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 6000\n",
            "Number of unique input tokens: 70\n",
            "Number of unique output tokens: 84\n",
            "Max sequence length for inputs: 26\n",
            "Max sequence length for outputs: 51\n"
          ]
        }
      ],
      "source": [
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split(\"\\t\")\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = \"\\t\" + target_text + \"\\n\"\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype=\"float32\",\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype=\"float32\",\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype=\"float32\",\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jTzOU7MGT2VJ"
      },
      "outputs": [],
      "source": [
        "# Define an input sequence and process it.\n",
        "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
        "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
        "\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "TTK4YkWmT2VJ",
        "outputId": "2027ab04-e2a7-4102-cada-c5765b856cac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.6798 - loss: 1.7884 - val_accuracy: 0.6541 - val_loss: 1.4796\n",
            "Epoch 2/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7342 - loss: 1.1074 - val_accuracy: 0.6581 - val_loss: 1.7484\n",
            "Epoch 3/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7360 - loss: 1.0546 - val_accuracy: 0.6682 - val_loss: 1.3018\n",
            "Epoch 4/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7455 - loss: 0.9828 - val_accuracy: 0.6702 - val_loss: 1.2704\n",
            "Epoch 5/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7557 - loss: 0.9354 - val_accuracy: 0.6799 - val_loss: 1.2154\n",
            "Epoch 6/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7624 - loss: 0.9093 - val_accuracy: 0.6806 - val_loss: 1.1961\n",
            "Epoch 7/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7683 - loss: 0.8704 - val_accuracy: 0.7079 - val_loss: 1.1240\n",
            "Epoch 8/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7740 - loss: 0.8530 - val_accuracy: 0.7062 - val_loss: 1.1080\n",
            "Epoch 9/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7808 - loss: 0.8218 - val_accuracy: 0.7124 - val_loss: 1.0807\n",
            "Epoch 10/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7823 - loss: 0.8125 - val_accuracy: 0.7160 - val_loss: 1.0636\n",
            "Epoch 11/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7868 - loss: 0.7943 - val_accuracy: 0.7169 - val_loss: 1.0561\n",
            "Epoch 12/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7888 - loss: 0.7870 - val_accuracy: 0.7239 - val_loss: 1.0345\n",
            "Epoch 13/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7919 - loss: 0.7749 - val_accuracy: 0.7283 - val_loss: 1.0199\n",
            "Epoch 14/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7947 - loss: 0.7603 - val_accuracy: 0.7257 - val_loss: 1.0258\n",
            "Epoch 15/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7960 - loss: 0.7550 - val_accuracy: 0.7298 - val_loss: 1.0060\n",
            "Epoch 16/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7977 - loss: 0.7475 - val_accuracy: 0.7277 - val_loss: 1.0156\n",
            "Epoch 17/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7984 - loss: 0.7422 - val_accuracy: 0.7352 - val_loss: 0.9859\n",
            "Epoch 18/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8012 - loss: 0.7318 - val_accuracy: 0.7387 - val_loss: 0.9763\n",
            "Epoch 19/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8033 - loss: 0.7247 - val_accuracy: 0.7396 - val_loss: 0.9712\n",
            "Epoch 20/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8045 - loss: 0.7200 - val_accuracy: 0.7415 - val_loss: 0.9645\n",
            "Epoch 21/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8056 - loss: 0.7142 - val_accuracy: 0.7426 - val_loss: 0.9621\n",
            "Epoch 22/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8098 - loss: 0.6965 - val_accuracy: 0.7416 - val_loss: 0.9555\n",
            "Epoch 23/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8083 - loss: 0.7007 - val_accuracy: 0.7435 - val_loss: 0.9526\n",
            "Epoch 24/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8102 - loss: 0.6949 - val_accuracy: 0.7461 - val_loss: 0.9419\n",
            "Epoch 25/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8114 - loss: 0.6867 - val_accuracy: 0.7441 - val_loss: 0.9443\n",
            "Epoch 26/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8133 - loss: 0.6799 - val_accuracy: 0.7450 - val_loss: 0.9421\n",
            "Epoch 27/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8160 - loss: 0.6699 - val_accuracy: 0.7484 - val_loss: 0.9297\n",
            "Epoch 28/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8164 - loss: 0.6675 - val_accuracy: 0.7522 - val_loss: 0.9172\n",
            "Epoch 29/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8181 - loss: 0.6618 - val_accuracy: 0.7481 - val_loss: 0.9266\n",
            "Epoch 30/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8187 - loss: 0.6575 - val_accuracy: 0.7517 - val_loss: 0.9202\n",
            "Epoch 31/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8216 - loss: 0.6460 - val_accuracy: 0.7544 - val_loss: 0.9051\n",
            "Epoch 32/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8218 - loss: 0.6420 - val_accuracy: 0.7555 - val_loss: 0.9037\n",
            "Epoch 33/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8257 - loss: 0.6323 - val_accuracy: 0.7519 - val_loss: 0.9140\n",
            "Epoch 34/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8258 - loss: 0.6333 - val_accuracy: 0.7593 - val_loss: 0.8922\n",
            "Epoch 35/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8265 - loss: 0.6273 - val_accuracy: 0.7595 - val_loss: 0.8894\n",
            "Epoch 36/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8279 - loss: 0.6231 - val_accuracy: 0.7590 - val_loss: 0.8894\n",
            "Epoch 37/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8286 - loss: 0.6217 - val_accuracy: 0.7619 - val_loss: 0.8807\n",
            "Epoch 38/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8322 - loss: 0.6091 - val_accuracy: 0.7628 - val_loss: 0.8821\n",
            "Epoch 39/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8332 - loss: 0.6020 - val_accuracy: 0.7647 - val_loss: 0.8738\n",
            "Epoch 40/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8359 - loss: 0.5970 - val_accuracy: 0.7650 - val_loss: 0.8669\n",
            "Epoch 41/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8371 - loss: 0.5866 - val_accuracy: 0.7609 - val_loss: 0.8850\n",
            "Epoch 42/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8362 - loss: 0.5898 - val_accuracy: 0.7660 - val_loss: 0.8644\n",
            "Epoch 43/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8364 - loss: 0.5908 - val_accuracy: 0.7661 - val_loss: 0.8640\n",
            "Epoch 44/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8404 - loss: 0.5769 - val_accuracy: 0.7651 - val_loss: 0.8732\n",
            "Epoch 45/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8407 - loss: 0.5749 - val_accuracy: 0.7700 - val_loss: 0.8593\n",
            "Epoch 46/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8415 - loss: 0.5732 - val_accuracy: 0.7676 - val_loss: 0.8620\n",
            "Epoch 47/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8453 - loss: 0.5618 - val_accuracy: 0.7669 - val_loss: 0.8659\n",
            "Epoch 48/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8456 - loss: 0.5591 - val_accuracy: 0.7707 - val_loss: 0.8538\n",
            "Epoch 49/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8466 - loss: 0.5569 - val_accuracy: 0.7705 - val_loss: 0.8524\n",
            "Epoch 50/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8484 - loss: 0.5472 - val_accuracy: 0.7719 - val_loss: 0.8508\n",
            "Epoch 51/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8485 - loss: 0.5466 - val_accuracy: 0.7709 - val_loss: 0.8501\n",
            "Epoch 52/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8510 - loss: 0.5384 - val_accuracy: 0.7730 - val_loss: 0.8466\n",
            "Epoch 53/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8515 - loss: 0.5370 - val_accuracy: 0.7732 - val_loss: 0.8451\n",
            "Epoch 54/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8533 - loss: 0.5297 - val_accuracy: 0.7737 - val_loss: 0.8430\n",
            "Epoch 55/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8538 - loss: 0.5285 - val_accuracy: 0.7743 - val_loss: 0.8480\n",
            "Epoch 56/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8578 - loss: 0.5129 - val_accuracy: 0.7747 - val_loss: 0.8497\n",
            "Epoch 57/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8568 - loss: 0.5167 - val_accuracy: 0.7748 - val_loss: 0.8428\n",
            "Epoch 58/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8600 - loss: 0.5083 - val_accuracy: 0.7760 - val_loss: 0.8432\n",
            "Epoch 59/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8608 - loss: 0.5039 - val_accuracy: 0.7766 - val_loss: 0.8434\n",
            "Epoch 60/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8623 - loss: 0.4965 - val_accuracy: 0.7773 - val_loss: 0.8405\n",
            "Epoch 61/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8622 - loss: 0.4966 - val_accuracy: 0.7778 - val_loss: 0.8388\n",
            "Epoch 62/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8645 - loss: 0.4890 - val_accuracy: 0.7762 - val_loss: 0.8436\n",
            "Epoch 63/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8651 - loss: 0.4849 - val_accuracy: 0.7750 - val_loss: 0.8480\n",
            "Epoch 64/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8695 - loss: 0.4752 - val_accuracy: 0.7781 - val_loss: 0.8466\n",
            "Epoch 65/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8697 - loss: 0.4707 - val_accuracy: 0.7769 - val_loss: 0.8517\n",
            "Epoch 66/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8707 - loss: 0.4682 - val_accuracy: 0.7745 - val_loss: 0.8525\n",
            "Epoch 67/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8711 - loss: 0.4646 - val_accuracy: 0.7776 - val_loss: 0.8473\n",
            "Epoch 68/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8736 - loss: 0.4573 - val_accuracy: 0.7764 - val_loss: 0.8516\n",
            "Epoch 69/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8737 - loss: 0.4562 - val_accuracy: 0.7773 - val_loss: 0.8535\n",
            "Epoch 70/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8760 - loss: 0.4484 - val_accuracy: 0.7787 - val_loss: 0.8488\n",
            "Epoch 71/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8762 - loss: 0.4435 - val_accuracy: 0.7762 - val_loss: 0.8625\n",
            "Epoch 72/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8779 - loss: 0.4394 - val_accuracy: 0.7775 - val_loss: 0.8586\n",
            "Epoch 73/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8789 - loss: 0.4386 - val_accuracy: 0.7783 - val_loss: 0.8600\n",
            "Epoch 74/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8799 - loss: 0.4316 - val_accuracy: 0.7775 - val_loss: 0.8631\n",
            "Epoch 75/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8822 - loss: 0.4253 - val_accuracy: 0.7774 - val_loss: 0.8644\n",
            "Epoch 76/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8823 - loss: 0.4237 - val_accuracy: 0.7785 - val_loss: 0.8614\n",
            "Epoch 77/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8838 - loss: 0.4194 - val_accuracy: 0.7789 - val_loss: 0.8696\n",
            "Epoch 78/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8841 - loss: 0.4175 - val_accuracy: 0.7783 - val_loss: 0.8739\n",
            "Epoch 79/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8857 - loss: 0.4129 - val_accuracy: 0.7775 - val_loss: 0.8785\n",
            "Epoch 80/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8884 - loss: 0.4020 - val_accuracy: 0.7785 - val_loss: 0.8791\n",
            "Epoch 81/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8897 - loss: 0.4013 - val_accuracy: 0.7753 - val_loss: 0.8896\n",
            "Epoch 82/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8916 - loss: 0.3913 - val_accuracy: 0.7766 - val_loss: 0.8848\n",
            "Epoch 83/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8908 - loss: 0.3926 - val_accuracy: 0.7759 - val_loss: 0.8946\n",
            "Epoch 84/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8942 - loss: 0.3821 - val_accuracy: 0.7766 - val_loss: 0.8944\n",
            "Epoch 85/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8924 - loss: 0.3852 - val_accuracy: 0.7775 - val_loss: 0.8970\n",
            "Epoch 86/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8956 - loss: 0.3772 - val_accuracy: 0.7762 - val_loss: 0.8997\n",
            "Epoch 87/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8983 - loss: 0.3676 - val_accuracy: 0.7764 - val_loss: 0.9043\n",
            "Epoch 88/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8976 - loss: 0.3697 - val_accuracy: 0.7768 - val_loss: 0.9074\n",
            "Epoch 89/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9004 - loss: 0.3586 - val_accuracy: 0.7757 - val_loss: 0.9110\n",
            "Epoch 90/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9007 - loss: 0.3591 - val_accuracy: 0.7764 - val_loss: 0.9147\n",
            "Epoch 91/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9006 - loss: 0.3588 - val_accuracy: 0.7774 - val_loss: 0.9239\n",
            "Epoch 92/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9035 - loss: 0.3488 - val_accuracy: 0.7763 - val_loss: 0.9254\n",
            "Epoch 93/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9037 - loss: 0.3465 - val_accuracy: 0.7758 - val_loss: 0.9301\n",
            "Epoch 94/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9043 - loss: 0.3458 - val_accuracy: 0.7749 - val_loss: 0.9276\n",
            "Epoch 95/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9048 - loss: 0.3439 - val_accuracy: 0.7764 - val_loss: 0.9352\n",
            "Epoch 96/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9070 - loss: 0.3358 - val_accuracy: 0.7765 - val_loss: 0.9420\n",
            "Epoch 97/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9077 - loss: 0.3320 - val_accuracy: 0.7751 - val_loss: 0.9490\n",
            "Epoch 98/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9076 - loss: 0.3310 - val_accuracy: 0.7736 - val_loss: 0.9586\n",
            "Epoch 99/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9112 - loss: 0.3191 - val_accuracy: 0.7747 - val_loss: 0.9509\n",
            "Epoch 100/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9134 - loss: 0.3133 - val_accuracy: 0.7745 - val_loss: 0.9659\n",
            "Epoch 101/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9127 - loss: 0.3148 - val_accuracy: 0.7741 - val_loss: 0.9635\n",
            "Epoch 102/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9155 - loss: 0.3073 - val_accuracy: 0.7741 - val_loss: 0.9678\n",
            "Epoch 103/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9157 - loss: 0.3051 - val_accuracy: 0.7764 - val_loss: 0.9721\n",
            "Epoch 104/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9165 - loss: 0.3045 - val_accuracy: 0.7755 - val_loss: 0.9752\n",
            "Epoch 105/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9176 - loss: 0.2960 - val_accuracy: 0.7742 - val_loss: 0.9857\n",
            "Epoch 106/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9191 - loss: 0.2943 - val_accuracy: 0.7740 - val_loss: 0.9918\n",
            "Epoch 107/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9189 - loss: 0.2919 - val_accuracy: 0.7747 - val_loss: 0.9924\n",
            "Epoch 108/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9205 - loss: 0.2870 - val_accuracy: 0.7746 - val_loss: 1.0032\n",
            "Epoch 109/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9215 - loss: 0.2831 - val_accuracy: 0.7742 - val_loss: 1.0021\n",
            "Epoch 110/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9228 - loss: 0.2802 - val_accuracy: 0.7717 - val_loss: 1.0135\n",
            "Epoch 111/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9233 - loss: 0.2790 - val_accuracy: 0.7731 - val_loss: 1.0184\n",
            "Epoch 112/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9235 - loss: 0.2756 - val_accuracy: 0.7726 - val_loss: 1.0291\n",
            "Epoch 113/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9246 - loss: 0.2713 - val_accuracy: 0.7732 - val_loss: 1.0269\n",
            "Epoch 114/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9263 - loss: 0.2670 - val_accuracy: 0.7729 - val_loss: 1.0311\n",
            "Epoch 115/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9279 - loss: 0.2621 - val_accuracy: 0.7736 - val_loss: 1.0432\n",
            "Epoch 116/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9283 - loss: 0.2603 - val_accuracy: 0.7725 - val_loss: 1.0506\n",
            "Epoch 117/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9301 - loss: 0.2544 - val_accuracy: 0.7721 - val_loss: 1.0546\n",
            "Epoch 118/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9311 - loss: 0.2515 - val_accuracy: 0.7722 - val_loss: 1.0572\n",
            "Epoch 119/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9329 - loss: 0.2472 - val_accuracy: 0.7729 - val_loss: 1.0576\n",
            "Epoch 120/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9321 - loss: 0.2481 - val_accuracy: 0.7709 - val_loss: 1.0741\n",
            "Epoch 121/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9320 - loss: 0.2459 - val_accuracy: 0.7712 - val_loss: 1.0719\n",
            "Epoch 122/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9344 - loss: 0.2409 - val_accuracy: 0.7705 - val_loss: 1.0772\n",
            "Epoch 123/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9353 - loss: 0.2366 - val_accuracy: 0.7710 - val_loss: 1.0900\n",
            "Epoch 124/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9366 - loss: 0.2322 - val_accuracy: 0.7715 - val_loss: 1.0979\n",
            "Epoch 125/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9371 - loss: 0.2287 - val_accuracy: 0.7704 - val_loss: 1.0961\n",
            "Epoch 126/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9381 - loss: 0.2271 - val_accuracy: 0.7730 - val_loss: 1.1018\n",
            "Epoch 127/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9379 - loss: 0.2275 - val_accuracy: 0.7710 - val_loss: 1.1090\n",
            "Epoch 128/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9389 - loss: 0.2225 - val_accuracy: 0.7695 - val_loss: 1.1163\n",
            "Epoch 129/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9399 - loss: 0.2211 - val_accuracy: 0.7715 - val_loss: 1.1250\n",
            "Epoch 130/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9418 - loss: 0.2156 - val_accuracy: 0.7695 - val_loss: 1.1330\n",
            "Epoch 131/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9416 - loss: 0.2133 - val_accuracy: 0.7697 - val_loss: 1.1336\n",
            "Epoch 132/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9427 - loss: 0.2105 - val_accuracy: 0.7703 - val_loss: 1.1419\n",
            "Epoch 133/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9435 - loss: 0.2072 - val_accuracy: 0.7693 - val_loss: 1.1460\n",
            "Epoch 134/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9420 - loss: 0.2105 - val_accuracy: 0.7715 - val_loss: 1.1471\n",
            "Epoch 135/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9454 - loss: 0.2011 - val_accuracy: 0.7715 - val_loss: 1.1497\n",
            "Epoch 136/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9456 - loss: 0.1991 - val_accuracy: 0.7697 - val_loss: 1.1621\n",
            "Epoch 137/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9462 - loss: 0.1974 - val_accuracy: 0.7697 - val_loss: 1.1689\n",
            "Epoch 138/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9467 - loss: 0.1953 - val_accuracy: 0.7680 - val_loss: 1.1850\n",
            "Epoch 139/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9472 - loss: 0.1929 - val_accuracy: 0.7694 - val_loss: 1.1801\n",
            "Epoch 140/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9483 - loss: 0.1908 - val_accuracy: 0.7689 - val_loss: 1.1899\n",
            "Epoch 141/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9494 - loss: 0.1861 - val_accuracy: 0.7698 - val_loss: 1.1989\n",
            "Epoch 142/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9507 - loss: 0.1816 - val_accuracy: 0.7694 - val_loss: 1.2085\n",
            "Epoch 143/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9489 - loss: 0.1852 - val_accuracy: 0.7694 - val_loss: 1.2042\n",
            "Epoch 144/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9512 - loss: 0.1799 - val_accuracy: 0.7669 - val_loss: 1.2176\n",
            "Epoch 145/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9512 - loss: 0.1790 - val_accuracy: 0.7680 - val_loss: 1.2282\n",
            "Epoch 146/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9513 - loss: 0.1771 - val_accuracy: 0.7676 - val_loss: 1.2238\n",
            "Epoch 147/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9523 - loss: 0.1742 - val_accuracy: 0.7689 - val_loss: 1.2307\n",
            "Epoch 148/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9540 - loss: 0.1703 - val_accuracy: 0.7694 - val_loss: 1.2270\n",
            "Epoch 149/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9547 - loss: 0.1669 - val_accuracy: 0.7683 - val_loss: 1.2451\n",
            "Epoch 150/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9549 - loss: 0.1660 - val_accuracy: 0.7669 - val_loss: 1.2541\n",
            "Epoch 151/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9557 - loss: 0.1636 - val_accuracy: 0.7672 - val_loss: 1.2529\n",
            "Epoch 152/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9567 - loss: 0.1597 - val_accuracy: 0.7684 - val_loss: 1.2612\n",
            "Epoch 153/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9564 - loss: 0.1622 - val_accuracy: 0.7662 - val_loss: 1.2733\n",
            "Epoch 154/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9565 - loss: 0.1600 - val_accuracy: 0.7679 - val_loss: 1.2694\n",
            "Epoch 155/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9584 - loss: 0.1542 - val_accuracy: 0.7685 - val_loss: 1.2741\n",
            "Epoch 156/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9579 - loss: 0.1556 - val_accuracy: 0.7675 - val_loss: 1.2853\n",
            "Epoch 157/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9549 - loss: 0.1636 - val_accuracy: 0.7665 - val_loss: 1.2911\n",
            "Epoch 158/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9586 - loss: 0.1521 - val_accuracy: 0.7684 - val_loss: 1.2933\n",
            "Epoch 159/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9608 - loss: 0.1470 - val_accuracy: 0.7674 - val_loss: 1.3012\n",
            "Epoch 160/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9611 - loss: 0.1440 - val_accuracy: 0.7674 - val_loss: 1.3011\n",
            "Epoch 161/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9615 - loss: 0.1418 - val_accuracy: 0.7656 - val_loss: 1.3229\n",
            "Epoch 162/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9609 - loss: 0.1432 - val_accuracy: 0.7674 - val_loss: 1.3310\n",
            "Epoch 163/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9622 - loss: 0.1393 - val_accuracy: 0.7665 - val_loss: 1.3327\n",
            "Epoch 164/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9632 - loss: 0.1373 - val_accuracy: 0.7665 - val_loss: 1.3327\n",
            "Epoch 165/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9615 - loss: 0.1396 - val_accuracy: 0.7661 - val_loss: 1.3412\n",
            "Epoch 166/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9645 - loss: 0.1326 - val_accuracy: 0.7663 - val_loss: 1.3492\n",
            "Epoch 167/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9635 - loss: 0.1331 - val_accuracy: 0.7665 - val_loss: 1.3492\n",
            "Epoch 168/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9649 - loss: 0.1299 - val_accuracy: 0.7663 - val_loss: 1.3573\n",
            "Epoch 169/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9646 - loss: 0.1313 - val_accuracy: 0.7668 - val_loss: 1.3562\n",
            "Epoch 170/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9660 - loss: 0.1266 - val_accuracy: 0.7656 - val_loss: 1.3695\n",
            "Epoch 171/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9657 - loss: 0.1272 - val_accuracy: 0.7664 - val_loss: 1.3704\n",
            "Epoch 172/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9662 - loss: 0.1257 - val_accuracy: 0.7660 - val_loss: 1.3816\n",
            "Epoch 173/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9677 - loss: 0.1207 - val_accuracy: 0.7642 - val_loss: 1.3861\n",
            "Epoch 174/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9671 - loss: 0.1218 - val_accuracy: 0.7656 - val_loss: 1.3879\n",
            "Epoch 175/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9676 - loss: 0.1206 - val_accuracy: 0.7672 - val_loss: 1.3929\n",
            "Epoch 176/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9687 - loss: 0.1171 - val_accuracy: 0.7642 - val_loss: 1.4039\n",
            "Epoch 177/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9694 - loss: 0.1140 - val_accuracy: 0.7638 - val_loss: 1.4116\n",
            "Epoch 178/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9693 - loss: 0.1144 - val_accuracy: 0.7637 - val_loss: 1.4116\n",
            "Epoch 179/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9693 - loss: 0.1123 - val_accuracy: 0.7647 - val_loss: 1.4166\n",
            "Epoch 180/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9698 - loss: 0.1112 - val_accuracy: 0.7656 - val_loss: 1.4241\n",
            "Epoch 181/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9694 - loss: 0.1115 - val_accuracy: 0.7654 - val_loss: 1.4346\n",
            "Epoch 182/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9696 - loss: 0.1100 - val_accuracy: 0.7647 - val_loss: 1.4285\n",
            "Epoch 183/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9706 - loss: 0.1075 - val_accuracy: 0.7625 - val_loss: 1.4419\n",
            "Epoch 184/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9698 - loss: 0.1094 - val_accuracy: 0.7647 - val_loss: 1.4353\n",
            "Epoch 185/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9728 - loss: 0.1025 - val_accuracy: 0.7648 - val_loss: 1.4453\n",
            "Epoch 186/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9716 - loss: 0.1039 - val_accuracy: 0.7638 - val_loss: 1.4629\n",
            "Epoch 187/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9720 - loss: 0.1032 - val_accuracy: 0.7643 - val_loss: 1.4595\n",
            "Epoch 188/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9729 - loss: 0.0993 - val_accuracy: 0.7645 - val_loss: 1.4626\n",
            "Epoch 189/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9724 - loss: 0.1021 - val_accuracy: 0.7655 - val_loss: 1.4719\n",
            "Epoch 190/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9740 - loss: 0.0980 - val_accuracy: 0.7647 - val_loss: 1.4670\n",
            "Epoch 191/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9737 - loss: 0.0967 - val_accuracy: 0.7646 - val_loss: 1.4872\n",
            "Epoch 192/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9735 - loss: 0.0963 - val_accuracy: 0.7643 - val_loss: 1.4838\n",
            "Epoch 193/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9748 - loss: 0.0934 - val_accuracy: 0.7647 - val_loss: 1.5020\n",
            "Epoch 194/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9743 - loss: 0.0931 - val_accuracy: 0.7638 - val_loss: 1.4979\n",
            "Epoch 195/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9749 - loss: 0.0921 - val_accuracy: 0.7634 - val_loss: 1.5076\n",
            "Epoch 196/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9756 - loss: 0.0913 - val_accuracy: 0.7659 - val_loss: 1.5081\n",
            "Epoch 197/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9754 - loss: 0.0902 - val_accuracy: 0.7637 - val_loss: 1.5271\n",
            "Epoch 198/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9752 - loss: 0.0914 - val_accuracy: 0.7628 - val_loss: 1.5262\n",
            "Epoch 199/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9765 - loss: 0.0867 - val_accuracy: 0.7648 - val_loss: 1.5244\n",
            "Epoch 200/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9767 - loss: 0.0853 - val_accuracy: 0.7644 - val_loss: 1.5314\n",
            "Epoch 201/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9769 - loss: 0.0845 - val_accuracy: 0.7641 - val_loss: 1.5413\n",
            "Epoch 202/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9769 - loss: 0.0861 - val_accuracy: 0.7654 - val_loss: 1.5401\n",
            "Epoch 203/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9773 - loss: 0.0841 - val_accuracy: 0.7622 - val_loss: 1.5540\n",
            "Epoch 204/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9777 - loss: 0.0819 - val_accuracy: 0.7613 - val_loss: 1.5516\n",
            "Epoch 205/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9786 - loss: 0.0795 - val_accuracy: 0.7648 - val_loss: 1.5539\n",
            "Epoch 206/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9778 - loss: 0.0814 - val_accuracy: 0.7637 - val_loss: 1.5607\n",
            "Epoch 207/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9777 - loss: 0.0818 - val_accuracy: 0.7633 - val_loss: 1.5522\n",
            "Epoch 208/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9780 - loss: 0.0822 - val_accuracy: 0.7634 - val_loss: 1.5644\n",
            "Epoch 209/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9790 - loss: 0.0773 - val_accuracy: 0.7634 - val_loss: 1.5774\n",
            "Epoch 210/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9795 - loss: 0.0757 - val_accuracy: 0.7623 - val_loss: 1.5757\n",
            "Epoch 211/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9800 - loss: 0.0743 - val_accuracy: 0.7631 - val_loss: 1.5803\n",
            "Epoch 212/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9798 - loss: 0.0747 - val_accuracy: 0.7640 - val_loss: 1.5868\n",
            "Epoch 213/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9798 - loss: 0.0741 - val_accuracy: 0.7641 - val_loss: 1.5885\n",
            "Epoch 214/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9802 - loss: 0.0722 - val_accuracy: 0.7639 - val_loss: 1.5905\n",
            "Epoch 215/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9808 - loss: 0.0713 - val_accuracy: 0.7624 - val_loss: 1.5977\n",
            "Epoch 216/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9807 - loss: 0.0707 - val_accuracy: 0.7627 - val_loss: 1.5967\n",
            "Epoch 217/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9807 - loss: 0.0711 - val_accuracy: 0.7621 - val_loss: 1.6159\n",
            "Epoch 218/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9813 - loss: 0.0686 - val_accuracy: 0.7636 - val_loss: 1.6195\n",
            "Epoch 219/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9808 - loss: 0.0696 - val_accuracy: 0.7627 - val_loss: 1.6291\n",
            "Epoch 220/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9821 - loss: 0.0659 - val_accuracy: 0.7632 - val_loss: 1.6396\n",
            "Epoch 221/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9818 - loss: 0.0681 - val_accuracy: 0.7633 - val_loss: 1.6304\n",
            "Epoch 222/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9821 - loss: 0.0658 - val_accuracy: 0.7631 - val_loss: 1.6471\n",
            "Epoch 223/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9820 - loss: 0.0666 - val_accuracy: 0.7620 - val_loss: 1.6414\n",
            "Epoch 224/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9817 - loss: 0.0670 - val_accuracy: 0.7634 - val_loss: 1.6476\n",
            "Epoch 225/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9815 - loss: 0.0668 - val_accuracy: 0.7627 - val_loss: 1.6490\n",
            "Epoch 226/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0638 - val_accuracy: 0.7617 - val_loss: 1.6557\n",
            "Epoch 227/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9825 - loss: 0.0628 - val_accuracy: 0.7623 - val_loss: 1.6591\n",
            "Epoch 228/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9831 - loss: 0.0622 - val_accuracy: 0.7623 - val_loss: 1.6739\n",
            "Epoch 229/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9837 - loss: 0.0610 - val_accuracy: 0.7622 - val_loss: 1.6702\n",
            "Epoch 230/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9839 - loss: 0.0595 - val_accuracy: 0.7622 - val_loss: 1.6779\n",
            "Epoch 231/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9835 - loss: 0.0611 - val_accuracy: 0.7633 - val_loss: 1.6697\n",
            "Epoch 232/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9847 - loss: 0.0572 - val_accuracy: 0.7636 - val_loss: 1.6762\n",
            "Epoch 233/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9843 - loss: 0.0571 - val_accuracy: 0.7630 - val_loss: 1.6784\n",
            "Epoch 234/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9836 - loss: 0.0594 - val_accuracy: 0.7621 - val_loss: 1.6916\n",
            "Epoch 235/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9845 - loss: 0.0565 - val_accuracy: 0.7625 - val_loss: 1.6976\n",
            "Epoch 236/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9852 - loss: 0.0551 - val_accuracy: 0.7632 - val_loss: 1.6905\n",
            "Epoch 237/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9843 - loss: 0.0571 - val_accuracy: 0.7621 - val_loss: 1.7015\n",
            "Epoch 238/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9857 - loss: 0.0545 - val_accuracy: 0.7636 - val_loss: 1.6987\n",
            "Epoch 239/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9850 - loss: 0.0549 - val_accuracy: 0.7616 - val_loss: 1.7097\n",
            "Epoch 240/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9850 - loss: 0.0543 - val_accuracy: 0.7621 - val_loss: 1.7200\n",
            "Epoch 241/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9863 - loss: 0.0517 - val_accuracy: 0.7622 - val_loss: 1.7151\n",
            "Epoch 242/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9856 - loss: 0.0520 - val_accuracy: 0.7610 - val_loss: 1.7270\n",
            "Epoch 243/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9852 - loss: 0.0534 - val_accuracy: 0.7612 - val_loss: 1.7193\n",
            "Epoch 244/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9864 - loss: 0.0502 - val_accuracy: 0.7625 - val_loss: 1.7317\n",
            "Epoch 245/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9862 - loss: 0.0508 - val_accuracy: 0.7637 - val_loss: 1.7313\n",
            "Epoch 246/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9857 - loss: 0.0527 - val_accuracy: 0.7607 - val_loss: 1.7471\n",
            "Epoch 247/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9863 - loss: 0.0499 - val_accuracy: 0.7620 - val_loss: 1.7489\n",
            "Epoch 248/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0491 - val_accuracy: 0.7638 - val_loss: 1.7335\n",
            "Epoch 249/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9864 - loss: 0.0491 - val_accuracy: 0.7626 - val_loss: 1.7493\n",
            "Epoch 250/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9867 - loss: 0.0484 - val_accuracy: 0.7625 - val_loss: 1.7474\n",
            "Epoch 251/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9871 - loss: 0.0471 - val_accuracy: 0.7619 - val_loss: 1.7587\n",
            "Epoch 252/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9877 - loss: 0.0458 - val_accuracy: 0.7608 - val_loss: 1.7614\n",
            "Epoch 253/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9867 - loss: 0.0492 - val_accuracy: 0.7632 - val_loss: 1.7653\n",
            "Epoch 254/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9872 - loss: 0.0468 - val_accuracy: 0.7622 - val_loss: 1.7755\n",
            "Epoch 255/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9875 - loss: 0.0455 - val_accuracy: 0.7611 - val_loss: 1.7694\n",
            "Epoch 256/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9871 - loss: 0.0467 - val_accuracy: 0.7611 - val_loss: 1.7719\n",
            "Epoch 257/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9873 - loss: 0.0466 - val_accuracy: 0.7617 - val_loss: 1.7784\n",
            "Epoch 258/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9874 - loss: 0.0462 - val_accuracy: 0.7616 - val_loss: 1.7821\n",
            "Epoch 259/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9882 - loss: 0.0438 - val_accuracy: 0.7629 - val_loss: 1.7795\n",
            "Epoch 260/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9886 - loss: 0.0429 - val_accuracy: 0.7603 - val_loss: 1.8001\n",
            "Epoch 261/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9887 - loss: 0.0421 - val_accuracy: 0.7607 - val_loss: 1.7996\n",
            "Epoch 262/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9881 - loss: 0.0430 - val_accuracy: 0.7623 - val_loss: 1.7886\n",
            "Epoch 263/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9886 - loss: 0.0417 - val_accuracy: 0.7613 - val_loss: 1.7990\n",
            "Epoch 264/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9884 - loss: 0.0422 - val_accuracy: 0.7628 - val_loss: 1.8032\n",
            "Epoch 265/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9884 - loss: 0.0429 - val_accuracy: 0.7605 - val_loss: 1.8160\n",
            "Epoch 266/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9888 - loss: 0.0412 - val_accuracy: 0.7619 - val_loss: 1.8020\n",
            "Epoch 267/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9896 - loss: 0.0396 - val_accuracy: 0.7625 - val_loss: 1.8169\n",
            "Epoch 268/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9891 - loss: 0.0397 - val_accuracy: 0.7625 - val_loss: 1.8163\n",
            "Epoch 269/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9892 - loss: 0.0395 - val_accuracy: 0.7611 - val_loss: 1.8184\n",
            "Epoch 270/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9893 - loss: 0.0391 - val_accuracy: 0.7606 - val_loss: 1.8313\n",
            "Epoch 271/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9900 - loss: 0.0374 - val_accuracy: 0.7615 - val_loss: 1.8230\n",
            "Epoch 272/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9894 - loss: 0.0384 - val_accuracy: 0.7625 - val_loss: 1.8291\n",
            "Epoch 273/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9900 - loss: 0.0381 - val_accuracy: 0.7623 - val_loss: 1.8298\n",
            "Epoch 274/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9891 - loss: 0.0399 - val_accuracy: 0.7617 - val_loss: 1.8287\n",
            "Epoch 275/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9899 - loss: 0.0374 - val_accuracy: 0.7624 - val_loss: 1.8398\n",
            "Epoch 276/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9900 - loss: 0.0370 - val_accuracy: 0.7616 - val_loss: 1.8436\n",
            "Epoch 277/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9892 - loss: 0.0390 - val_accuracy: 0.7623 - val_loss: 1.8425\n",
            "Epoch 278/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9900 - loss: 0.0366 - val_accuracy: 0.7627 - val_loss: 1.8563\n",
            "Epoch 279/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9894 - loss: 0.0374 - val_accuracy: 0.7622 - val_loss: 1.8555\n",
            "Epoch 280/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9901 - loss: 0.0359 - val_accuracy: 0.7621 - val_loss: 1.8626\n",
            "Epoch 281/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9902 - loss: 0.0350 - val_accuracy: 0.7620 - val_loss: 1.8574\n",
            "Epoch 282/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9904 - loss: 0.0341 - val_accuracy: 0.7601 - val_loss: 1.8718\n",
            "Epoch 283/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9909 - loss: 0.0339 - val_accuracy: 0.7616 - val_loss: 1.8702\n",
            "Epoch 284/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9910 - loss: 0.0329 - val_accuracy: 0.7617 - val_loss: 1.8689\n",
            "Epoch 285/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9909 - loss: 0.0336 - val_accuracy: 0.7620 - val_loss: 1.8681\n",
            "Epoch 286/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9914 - loss: 0.0320 - val_accuracy: 0.7619 - val_loss: 1.8794\n",
            "Epoch 287/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9905 - loss: 0.0352 - val_accuracy: 0.7605 - val_loss: 1.8743\n",
            "Epoch 288/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9908 - loss: 0.0333 - val_accuracy: 0.7623 - val_loss: 1.8797\n",
            "Epoch 289/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9901 - loss: 0.0361 - val_accuracy: 0.7620 - val_loss: 1.8921\n",
            "Epoch 290/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9911 - loss: 0.0323 - val_accuracy: 0.7605 - val_loss: 1.8872\n",
            "Epoch 291/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9914 - loss: 0.0315 - val_accuracy: 0.7626 - val_loss: 1.8968\n",
            "Epoch 292/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9916 - loss: 0.0308 - val_accuracy: 0.7616 - val_loss: 1.8965\n",
            "Epoch 293/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9917 - loss: 0.0304 - val_accuracy: 0.7607 - val_loss: 1.8951\n",
            "Epoch 294/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9912 - loss: 0.0316 - val_accuracy: 0.7611 - val_loss: 1.9042\n",
            "Epoch 295/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9911 - loss: 0.0324 - val_accuracy: 0.7629 - val_loss: 1.8960\n",
            "Epoch 296/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9915 - loss: 0.0310 - val_accuracy: 0.7615 - val_loss: 1.9080\n",
            "Epoch 297/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9912 - loss: 0.0314 - val_accuracy: 0.7616 - val_loss: 1.9117\n",
            "Epoch 298/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9922 - loss: 0.0290 - val_accuracy: 0.7614 - val_loss: 1.9014\n",
            "Epoch 299/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9914 - loss: 0.0306 - val_accuracy: 0.7619 - val_loss: 1.9111\n",
            "Epoch 300/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9922 - loss: 0.0286 - val_accuracy: 0.7606 - val_loss: 1.9333\n",
            "Epoch 301/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9923 - loss: 0.0283 - val_accuracy: 0.7606 - val_loss: 1.9240\n",
            "Epoch 302/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9918 - loss: 0.0298 - val_accuracy: 0.7609 - val_loss: 1.9259\n",
            "Epoch 303/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9925 - loss: 0.0281 - val_accuracy: 0.7615 - val_loss: 1.9332\n",
            "Epoch 304/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9923 - loss: 0.0282 - val_accuracy: 0.7609 - val_loss: 1.9286\n",
            "Epoch 305/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9902 - loss: 0.0344 - val_accuracy: 0.7620 - val_loss: 1.9218\n",
            "Epoch 306/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9927 - loss: 0.0277 - val_accuracy: 0.7616 - val_loss: 1.9334\n",
            "Epoch 307/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9923 - loss: 0.0284 - val_accuracy: 0.7621 - val_loss: 1.9277\n",
            "Epoch 308/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9926 - loss: 0.0273 - val_accuracy: 0.7609 - val_loss: 1.9428\n",
            "Epoch 309/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9922 - loss: 0.0278 - val_accuracy: 0.7610 - val_loss: 1.9389\n",
            "Epoch 310/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9921 - loss: 0.0282 - val_accuracy: 0.7612 - val_loss: 1.9425\n",
            "Epoch 311/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9923 - loss: 0.0280 - val_accuracy: 0.7602 - val_loss: 1.9351\n",
            "Epoch 312/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9926 - loss: 0.0263 - val_accuracy: 0.7619 - val_loss: 1.9430\n",
            "Epoch 313/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9929 - loss: 0.0262 - val_accuracy: 0.7627 - val_loss: 1.9472\n",
            "Epoch 314/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9929 - loss: 0.0263 - val_accuracy: 0.7619 - val_loss: 1.9445\n",
            "Epoch 315/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9923 - loss: 0.0276 - val_accuracy: 0.7624 - val_loss: 1.9604\n",
            "Epoch 316/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9921 - loss: 0.0281 - val_accuracy: 0.7613 - val_loss: 1.9579\n",
            "Epoch 317/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9931 - loss: 0.0252 - val_accuracy: 0.7620 - val_loss: 1.9602\n",
            "Epoch 318/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9928 - loss: 0.0259 - val_accuracy: 0.7613 - val_loss: 1.9578\n",
            "Epoch 319/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9931 - loss: 0.0249 - val_accuracy: 0.7615 - val_loss: 1.9661\n",
            "Epoch 320/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9931 - loss: 0.0252 - val_accuracy: 0.7603 - val_loss: 1.9642\n",
            "Epoch 321/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9928 - loss: 0.0255 - val_accuracy: 0.7606 - val_loss: 1.9714\n",
            "Epoch 322/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9930 - loss: 0.0250 - val_accuracy: 0.7610 - val_loss: 1.9624\n",
            "Epoch 323/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9930 - loss: 0.0250 - val_accuracy: 0.7608 - val_loss: 1.9812\n",
            "Epoch 324/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9931 - loss: 0.0251 - val_accuracy: 0.7621 - val_loss: 1.9655\n",
            "Epoch 325/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9928 - loss: 0.0255 - val_accuracy: 0.7613 - val_loss: 1.9737\n",
            "Epoch 326/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9936 - loss: 0.0237 - val_accuracy: 0.7617 - val_loss: 1.9755\n",
            "Epoch 327/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9933 - loss: 0.0240 - val_accuracy: 0.7618 - val_loss: 1.9763\n",
            "Epoch 328/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9922 - loss: 0.0276 - val_accuracy: 0.7635 - val_loss: 1.9689\n",
            "Epoch 329/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9934 - loss: 0.0240 - val_accuracy: 0.7615 - val_loss: 1.9782\n",
            "Epoch 330/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9934 - loss: 0.0238 - val_accuracy: 0.7621 - val_loss: 1.9862\n",
            "Epoch 331/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9931 - loss: 0.0237 - val_accuracy: 0.7609 - val_loss: 1.9843\n",
            "Epoch 332/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9935 - loss: 0.0235 - val_accuracy: 0.7611 - val_loss: 1.9942\n",
            "Epoch 333/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9931 - loss: 0.0243 - val_accuracy: 0.7609 - val_loss: 1.9849\n",
            "Epoch 334/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9934 - loss: 0.0234 - val_accuracy: 0.7610 - val_loss: 2.0005\n",
            "Epoch 335/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9933 - loss: 0.0234 - val_accuracy: 0.7607 - val_loss: 1.9974\n",
            "Epoch 336/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9928 - loss: 0.0247 - val_accuracy: 0.7608 - val_loss: 2.0048\n",
            "Epoch 337/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9935 - loss: 0.0232 - val_accuracy: 0.7606 - val_loss: 1.9847\n",
            "Epoch 338/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9933 - loss: 0.0229 - val_accuracy: 0.7598 - val_loss: 2.0164\n",
            "Epoch 339/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9936 - loss: 0.0222 - val_accuracy: 0.7619 - val_loss: 2.0072\n",
            "Epoch 340/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9935 - loss: 0.0229 - val_accuracy: 0.7621 - val_loss: 2.0072\n",
            "Epoch 341/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9930 - loss: 0.0244 - val_accuracy: 0.7612 - val_loss: 2.0066\n",
            "Epoch 342/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9936 - loss: 0.0219 - val_accuracy: 0.7604 - val_loss: 2.0161\n",
            "Epoch 343/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9937 - loss: 0.0225 - val_accuracy: 0.7624 - val_loss: 1.9961\n",
            "Epoch 344/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9936 - loss: 0.0221 - val_accuracy: 0.7614 - val_loss: 2.0095\n",
            "Epoch 345/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9937 - loss: 0.0221 - val_accuracy: 0.7605 - val_loss: 2.0220\n",
            "Epoch 346/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9936 - loss: 0.0221 - val_accuracy: 0.7605 - val_loss: 2.0220\n",
            "Epoch 347/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9935 - loss: 0.0230 - val_accuracy: 0.7614 - val_loss: 2.0205\n",
            "Epoch 348/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9938 - loss: 0.0216 - val_accuracy: 0.7609 - val_loss: 2.0249\n",
            "Epoch 349/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9936 - loss: 0.0212 - val_accuracy: 0.7621 - val_loss: 2.0124\n",
            "Epoch 350/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9940 - loss: 0.0205 - val_accuracy: 0.7609 - val_loss: 2.0232\n",
            "Epoch 351/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9941 - loss: 0.0203 - val_accuracy: 0.7611 - val_loss: 2.0262\n",
            "Epoch 352/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9941 - loss: 0.0214 - val_accuracy: 0.7617 - val_loss: 2.0322\n",
            "Epoch 353/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9943 - loss: 0.0205 - val_accuracy: 0.7616 - val_loss: 2.0255\n",
            "Epoch 354/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9944 - loss: 0.0204 - val_accuracy: 0.7628 - val_loss: 2.0310\n",
            "Epoch 355/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9940 - loss: 0.0203 - val_accuracy: 0.7606 - val_loss: 2.0529\n",
            "Epoch 356/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9937 - loss: 0.0216 - val_accuracy: 0.7609 - val_loss: 2.0495\n",
            "Epoch 357/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9937 - loss: 0.0216 - val_accuracy: 0.7623 - val_loss: 2.0330\n",
            "Epoch 358/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9939 - loss: 0.0213 - val_accuracy: 0.7620 - val_loss: 2.0376\n",
            "Epoch 359/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9942 - loss: 0.0197 - val_accuracy: 0.7629 - val_loss: 2.0418\n",
            "Epoch 360/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9944 - loss: 0.0196 - val_accuracy: 0.7620 - val_loss: 2.0414\n",
            "Epoch 361/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9946 - loss: 0.0189 - val_accuracy: 0.7607 - val_loss: 2.0522\n",
            "Epoch 362/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9937 - loss: 0.0209 - val_accuracy: 0.7607 - val_loss: 2.0609\n",
            "Epoch 363/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9946 - loss: 0.0185 - val_accuracy: 0.7612 - val_loss: 2.0456\n",
            "Epoch 364/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9943 - loss: 0.0193 - val_accuracy: 0.7611 - val_loss: 2.0535\n",
            "Epoch 365/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9941 - loss: 0.0198 - val_accuracy: 0.7613 - val_loss: 2.0643\n",
            "Epoch 366/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9943 - loss: 0.0193 - val_accuracy: 0.7634 - val_loss: 2.0524\n",
            "Epoch 367/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9942 - loss: 0.0201 - val_accuracy: 0.7614 - val_loss: 2.0591\n",
            "Epoch 368/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9944 - loss: 0.0189 - val_accuracy: 0.7607 - val_loss: 2.0622\n",
            "Epoch 369/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9935 - loss: 0.0213 - val_accuracy: 0.7610 - val_loss: 2.0615\n",
            "Epoch 370/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9940 - loss: 0.0194 - val_accuracy: 0.7618 - val_loss: 2.0614\n",
            "Epoch 371/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9937 - loss: 0.0200 - val_accuracy: 0.7619 - val_loss: 2.0534\n",
            "Epoch 372/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9935 - loss: 0.0216 - val_accuracy: 0.7620 - val_loss: 2.0652\n",
            "Epoch 373/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9932 - loss: 0.0225 - val_accuracy: 0.7614 - val_loss: 2.0593\n",
            "Epoch 374/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9941 - loss: 0.0197 - val_accuracy: 0.7617 - val_loss: 2.0671\n",
            "Epoch 375/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9946 - loss: 0.0186 - val_accuracy: 0.7612 - val_loss: 2.0705\n",
            "Epoch 376/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9940 - loss: 0.0197 - val_accuracy: 0.7626 - val_loss: 2.0651\n",
            "Epoch 377/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9949 - loss: 0.0174 - val_accuracy: 0.7630 - val_loss: 2.0629\n",
            "Epoch 378/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9947 - loss: 0.0182 - val_accuracy: 0.7627 - val_loss: 2.0757\n",
            "Epoch 379/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9939 - loss: 0.0202 - val_accuracy: 0.7621 - val_loss: 2.0756\n",
            "Epoch 380/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9944 - loss: 0.0181 - val_accuracy: 0.7626 - val_loss: 2.0612\n",
            "Epoch 381/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9945 - loss: 0.0185 - val_accuracy: 0.7623 - val_loss: 2.0750\n",
            "Epoch 382/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9949 - loss: 0.0174 - val_accuracy: 0.7618 - val_loss: 2.0827\n",
            "Epoch 383/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9943 - loss: 0.0185 - val_accuracy: 0.7607 - val_loss: 2.0871\n",
            "Epoch 384/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9945 - loss: 0.0179 - val_accuracy: 0.7626 - val_loss: 2.0697\n",
            "Epoch 385/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9949 - loss: 0.0173 - val_accuracy: 0.7607 - val_loss: 2.0902\n",
            "Epoch 386/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9944 - loss: 0.0182 - val_accuracy: 0.7630 - val_loss: 2.0842\n",
            "Epoch 387/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9939 - loss: 0.0199 - val_accuracy: 0.7615 - val_loss: 2.0732\n",
            "Epoch 388/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9946 - loss: 0.0180 - val_accuracy: 0.7617 - val_loss: 2.0783\n",
            "Epoch 389/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9935 - loss: 0.0221 - val_accuracy: 0.7610 - val_loss: 2.0830\n",
            "Epoch 390/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9941 - loss: 0.0190 - val_accuracy: 0.7612 - val_loss: 2.0854\n",
            "Epoch 391/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9945 - loss: 0.0175 - val_accuracy: 0.7625 - val_loss: 2.0818\n",
            "Epoch 392/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9948 - loss: 0.0175 - val_accuracy: 0.7613 - val_loss: 2.0896\n",
            "Epoch 393/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9947 - loss: 0.0177 - val_accuracy: 0.7622 - val_loss: 2.0839\n",
            "Epoch 394/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9946 - loss: 0.0181 - val_accuracy: 0.7623 - val_loss: 2.0888\n",
            "Epoch 395/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9947 - loss: 0.0177 - val_accuracy: 0.7615 - val_loss: 2.0826\n",
            "Epoch 396/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9942 - loss: 0.0189 - val_accuracy: 0.7607 - val_loss: 2.1026\n",
            "Epoch 397/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9942 - loss: 0.0182 - val_accuracy: 0.7627 - val_loss: 2.0940\n",
            "Epoch 398/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9944 - loss: 0.0180 - val_accuracy: 0.7625 - val_loss: 2.1065\n",
            "Epoch 399/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9946 - loss: 0.0170 - val_accuracy: 0.7615 - val_loss: 2.1085\n",
            "Epoch 400/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9949 - loss: 0.0161 - val_accuracy: 0.7626 - val_loss: 2.1072\n",
            "Epoch 401/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9943 - loss: 0.0181 - val_accuracy: 0.7620 - val_loss: 2.0916\n",
            "Epoch 402/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9947 - loss: 0.0168 - val_accuracy: 0.7621 - val_loss: 2.1038\n",
            "Epoch 403/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9948 - loss: 0.0164 - val_accuracy: 0.7608 - val_loss: 2.1015\n",
            "Epoch 404/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9947 - loss: 0.0170 - val_accuracy: 0.7620 - val_loss: 2.1072\n",
            "Epoch 405/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9948 - loss: 0.0162 - val_accuracy: 0.7615 - val_loss: 2.1007\n",
            "Epoch 406/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9950 - loss: 0.0156 - val_accuracy: 0.7623 - val_loss: 2.1180\n",
            "Epoch 407/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9950 - loss: 0.0160 - val_accuracy: 0.7614 - val_loss: 2.1142\n",
            "Epoch 408/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9947 - loss: 0.0162 - val_accuracy: 0.7626 - val_loss: 2.0953\n",
            "Epoch 409/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9953 - loss: 0.0150 - val_accuracy: 0.7614 - val_loss: 2.1192\n",
            "Epoch 410/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9952 - loss: 0.0149 - val_accuracy: 0.7613 - val_loss: 2.1231\n",
            "Epoch 411/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9948 - loss: 0.0163 - val_accuracy: 0.7625 - val_loss: 2.1147\n",
            "Epoch 412/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9951 - loss: 0.0156 - val_accuracy: 0.7617 - val_loss: 2.1189\n",
            "Epoch 413/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9948 - loss: 0.0156 - val_accuracy: 0.7622 - val_loss: 2.1237\n",
            "Epoch 414/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9949 - loss: 0.0158 - val_accuracy: 0.7615 - val_loss: 2.1262\n",
            "Epoch 415/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9945 - loss: 0.0166 - val_accuracy: 0.7618 - val_loss: 2.1362\n",
            "Epoch 416/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9948 - loss: 0.0161 - val_accuracy: 0.7613 - val_loss: 2.1257\n",
            "Epoch 417/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9952 - loss: 0.0149 - val_accuracy: 0.7620 - val_loss: 2.1184\n",
            "Epoch 418/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.9955 - loss: 0.0142 - val_accuracy: 0.7617 - val_loss: 2.1300\n",
            "Epoch 419/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9948 - loss: 0.0159 - val_accuracy: 0.7615 - val_loss: 2.1306\n",
            "Epoch 420/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9947 - loss: 0.0161 - val_accuracy: 0.7605 - val_loss: 2.1306\n",
            "Epoch 421/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9950 - loss: 0.0149 - val_accuracy: 0.7622 - val_loss: 2.1238\n",
            "Epoch 422/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9948 - loss: 0.0165 - val_accuracy: 0.7622 - val_loss: 2.1253\n",
            "Epoch 423/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9941 - loss: 0.0174 - val_accuracy: 0.7621 - val_loss: 2.1255\n",
            "Epoch 424/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9949 - loss: 0.0163 - val_accuracy: 0.7617 - val_loss: 2.1308\n",
            "Epoch 425/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9947 - loss: 0.0159 - val_accuracy: 0.7622 - val_loss: 2.1253\n",
            "Epoch 426/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9950 - loss: 0.0156 - val_accuracy: 0.7629 - val_loss: 2.1285\n",
            "Epoch 427/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9952 - loss: 0.0146 - val_accuracy: 0.7614 - val_loss: 2.1398\n",
            "Epoch 428/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9948 - loss: 0.0162 - val_accuracy: 0.7624 - val_loss: 2.1268\n",
            "Epoch 429/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9948 - loss: 0.0158 - val_accuracy: 0.7621 - val_loss: 2.1289\n",
            "Epoch 430/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9942 - loss: 0.0178 - val_accuracy: 0.7612 - val_loss: 2.1353\n",
            "Epoch 431/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9951 - loss: 0.0152 - val_accuracy: 0.7615 - val_loss: 2.1458\n",
            "Epoch 432/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9947 - loss: 0.0160 - val_accuracy: 0.7624 - val_loss: 2.1316\n",
            "Epoch 433/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9951 - loss: 0.0151 - val_accuracy: 0.7623 - val_loss: 2.1376\n",
            "Epoch 434/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9946 - loss: 0.0163 - val_accuracy: 0.7612 - val_loss: 2.1471\n",
            "Epoch 435/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9947 - loss: 0.0160 - val_accuracy: 0.7619 - val_loss: 2.1373\n",
            "Epoch 436/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9952 - loss: 0.0144 - val_accuracy: 0.7635 - val_loss: 2.1440\n",
            "Epoch 437/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9950 - loss: 0.0147 - val_accuracy: 0.7616 - val_loss: 2.1383\n",
            "Epoch 438/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9954 - loss: 0.0139 - val_accuracy: 0.7622 - val_loss: 2.1413\n",
            "Epoch 439/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9954 - loss: 0.0139 - val_accuracy: 0.7624 - val_loss: 2.1472\n",
            "Epoch 440/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9949 - loss: 0.0151 - val_accuracy: 0.7616 - val_loss: 2.1553\n",
            "Epoch 441/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9954 - loss: 0.0136 - val_accuracy: 0.7609 - val_loss: 2.1595\n",
            "Epoch 442/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9951 - loss: 0.0141 - val_accuracy: 0.7614 - val_loss: 2.1527\n",
            "Epoch 443/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9955 - loss: 0.0135 - val_accuracy: 0.7626 - val_loss: 2.1483\n",
            "Epoch 444/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9950 - loss: 0.0147 - val_accuracy: 0.7624 - val_loss: 2.1497\n",
            "Epoch 445/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9951 - loss: 0.0138 - val_accuracy: 0.7617 - val_loss: 2.1591\n",
            "Epoch 446/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9949 - loss: 0.0148 - val_accuracy: 0.7613 - val_loss: 2.1609\n",
            "Epoch 447/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9953 - loss: 0.0141 - val_accuracy: 0.7605 - val_loss: 2.1838\n",
            "Epoch 448/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9945 - loss: 0.0166 - val_accuracy: 0.7609 - val_loss: 2.1655\n",
            "Epoch 449/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.9943 - loss: 0.0168 - val_accuracy: 0.7622 - val_loss: 2.1530\n",
            "Epoch 450/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9948 - loss: 0.0151 - val_accuracy: 0.7621 - val_loss: 2.1681\n",
            "Epoch 451/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9948 - loss: 0.0154 - val_accuracy: 0.7620 - val_loss: 2.1620\n",
            "Epoch 452/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9950 - loss: 0.0144 - val_accuracy: 0.7609 - val_loss: 2.1565\n",
            "Epoch 453/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9953 - loss: 0.0140 - val_accuracy: 0.7625 - val_loss: 2.1555\n",
            "Epoch 454/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9953 - loss: 0.0142 - val_accuracy: 0.7622 - val_loss: 2.1590\n",
            "Epoch 455/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9954 - loss: 0.0138 - val_accuracy: 0.7616 - val_loss: 2.1633\n",
            "Epoch 456/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9955 - loss: 0.0132 - val_accuracy: 0.7618 - val_loss: 2.1538\n",
            "Epoch 457/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9950 - loss: 0.0144 - val_accuracy: 0.7635 - val_loss: 2.1585\n",
            "Epoch 458/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9955 - loss: 0.0132 - val_accuracy: 0.7619 - val_loss: 2.1671\n",
            "Epoch 459/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9952 - loss: 0.0143 - val_accuracy: 0.7628 - val_loss: 2.1706\n",
            "Epoch 460/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9954 - loss: 0.0131 - val_accuracy: 0.7627 - val_loss: 2.1643\n",
            "Epoch 461/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9956 - loss: 0.0125 - val_accuracy: 0.7616 - val_loss: 2.1693\n",
            "Epoch 462/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9953 - loss: 0.0131 - val_accuracy: 0.7617 - val_loss: 2.1700\n",
            "Epoch 463/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9948 - loss: 0.0139 - val_accuracy: 0.7623 - val_loss: 2.1733\n",
            "Epoch 464/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9948 - loss: 0.0148 - val_accuracy: 0.7630 - val_loss: 2.1681\n",
            "Epoch 465/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9949 - loss: 0.0143 - val_accuracy: 0.7627 - val_loss: 2.1696\n",
            "Epoch 466/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9946 - loss: 0.0156 - val_accuracy: 0.7622 - val_loss: 2.1658\n",
            "Epoch 467/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9952 - loss: 0.0137 - val_accuracy: 0.7630 - val_loss: 2.1671\n",
            "Epoch 468/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9954 - loss: 0.0131 - val_accuracy: 0.7615 - val_loss: 2.1793\n",
            "Epoch 469/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9945 - loss: 0.0170 - val_accuracy: 0.7615 - val_loss: 2.1821\n",
            "Epoch 470/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9943 - loss: 0.0177 - val_accuracy: 0.7621 - val_loss: 2.1716\n",
            "Epoch 471/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9951 - loss: 0.0139 - val_accuracy: 0.7623 - val_loss: 2.1750\n",
            "Epoch 472/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9952 - loss: 0.0138 - val_accuracy: 0.7623 - val_loss: 2.1773\n",
            "Epoch 473/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9951 - loss: 0.0144 - val_accuracy: 0.7614 - val_loss: 2.1690\n",
            "Epoch 474/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9954 - loss: 0.0133 - val_accuracy: 0.7617 - val_loss: 2.1857\n",
            "Epoch 475/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9951 - loss: 0.0139 - val_accuracy: 0.7619 - val_loss: 2.1880\n",
            "Epoch 476/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9954 - loss: 0.0133 - val_accuracy: 0.7612 - val_loss: 2.1852\n",
            "Epoch 477/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9951 - loss: 0.0140 - val_accuracy: 0.7633 - val_loss: 2.1779\n",
            "Epoch 478/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9951 - loss: 0.0136 - val_accuracy: 0.7613 - val_loss: 2.1727\n",
            "Epoch 479/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9953 - loss: 0.0131 - val_accuracy: 0.7618 - val_loss: 2.1934\n",
            "Epoch 480/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9952 - loss: 0.0137 - val_accuracy: 0.7607 - val_loss: 2.1897\n",
            "Epoch 481/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9950 - loss: 0.0139 - val_accuracy: 0.7607 - val_loss: 2.1845\n",
            "Epoch 482/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9951 - loss: 0.0132 - val_accuracy: 0.7617 - val_loss: 2.1767\n",
            "Epoch 483/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9948 - loss: 0.0144 - val_accuracy: 0.7609 - val_loss: 2.1926\n",
            "Epoch 484/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9955 - loss: 0.0126 - val_accuracy: 0.7631 - val_loss: 2.1853\n",
            "Epoch 485/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9953 - loss: 0.0138 - val_accuracy: 0.7618 - val_loss: 2.1744\n",
            "Epoch 486/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9945 - loss: 0.0162 - val_accuracy: 0.7615 - val_loss: 2.1733\n",
            "Epoch 487/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9952 - loss: 0.0131 - val_accuracy: 0.7617 - val_loss: 2.1813\n",
            "Epoch 488/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9954 - loss: 0.0129 - val_accuracy: 0.7620 - val_loss: 2.1897\n",
            "Epoch 489/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9952 - loss: 0.0133 - val_accuracy: 0.7625 - val_loss: 2.1793\n",
            "Epoch 490/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9954 - loss: 0.0128 - val_accuracy: 0.7621 - val_loss: 2.1869\n",
            "Epoch 491/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9950 - loss: 0.0135 - val_accuracy: 0.7616 - val_loss: 2.1943\n",
            "Epoch 492/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9954 - loss: 0.0129 - val_accuracy: 0.7626 - val_loss: 2.2056\n",
            "Epoch 493/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9956 - loss: 0.0125 - val_accuracy: 0.7620 - val_loss: 2.2020\n",
            "Epoch 494/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9956 - loss: 0.0123 - val_accuracy: 0.7607 - val_loss: 2.1906\n",
            "Epoch 495/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9957 - loss: 0.0117 - val_accuracy: 0.7621 - val_loss: 2.1997\n",
            "Epoch 496/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9955 - loss: 0.0119 - val_accuracy: 0.7625 - val_loss: 2.1931\n",
            "Epoch 497/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9954 - loss: 0.0124 - val_accuracy: 0.7617 - val_loss: 2.2026\n",
            "Epoch 498/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9954 - loss: 0.0124 - val_accuracy: 0.7620 - val_loss: 2.2021\n",
            "Epoch 499/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9953 - loss: 0.0133 - val_accuracy: 0.7626 - val_loss: 2.2018\n",
            "Epoch 500/500\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9950 - loss: 0.0137 - val_accuracy: 0.7625 - val_loss: 2.1991\n"
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.2,\n",
        ")\n",
        "# Save model\n",
        "model.save(\"s2s_model.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_7I9riZT2VK"
      },
      "source": [
        "## Run inference (sampling)\n",
        "\n",
        "1. encode input and retrieve initial decoder state\n",
        "2. run one step of decoder with this initial state\n",
        "and a \"start of sequence\" token as target.\n",
        "Output will be the next target token.\n",
        "3. Repeat with the current target token and current states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "MYdvMr2OT2VK"
      },
      "outputs": [],
      "source": [
        "# Define sampling models\n",
        "# Restore the model and construct the encoder and decoder.\n",
        "model = keras.models.load_model(\"s2s_model.keras\")\n",
        "\n",
        "encoder_inputs = model.input[0]  # input_1\n",
        "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_inputs = model.input[1]  # input_2\n",
        "decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_lstm = model.layers[3]\n",
        "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs\n",
        ")\n",
        "decoder_states = [state_h_dec, state_c_dec]\n",
        "decoder_dense = model.layers[4]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = keras.Model(\n",
        "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        ")\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq, verbose=0)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value, verbose=0\n",
        "        )\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "    return decoded_sentence\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc1lUBL3T2VK"
      },
      "source": [
        "You can now generate decoded sentences as such:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5gse7K57T2VK",
        "outputId": "f0d4cbdf-e49c-4c0a-ba4c-1cdc758eb2bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: مرحبًا.\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: اركض!\n",
            "\n",
            "-\n",
            "Input sentence: Duck!\n",
            "Decoded sentence: اخفضي رأسك!\n",
            "\n",
            "-\n",
            "Input sentence: Duck!\n",
            "Decoded sentence: اخفضي رأسك!\n",
            "\n",
            "-\n",
            "Input sentence: Duck!\n",
            "Decoded sentence: اخفضي رأسك!\n",
            "\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: النجدة!\n",
            "\n",
            "-\n",
            "Input sentence: Jump!\n",
            "Decoded sentence: اقفز!\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: قف!\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: قف!\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: إنتظر\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: داوم.\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: داوم.\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: مرحباً.\n",
            "\n",
            "-\n",
            "Input sentence: Hello.\n",
            "Decoded sentence: مرحباً.\n",
            "\n",
            "-\n",
            "Input sentence: Hello.\n",
            "Decoded sentence: مرحباً.\n",
            "\n",
            "-\n",
            "Input sentence: Hurry!\n",
            "Decoded sentence: تعجّل!\n",
            "\n",
            "-\n",
            "Input sentence: Hurry!\n",
            "Decoded sentence: تعجّل!\n",
            "\n",
            "-\n",
            "Input sentence: I see.\n",
            "Decoded sentence: انا اري\n",
            "\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: أنا فُزت!\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: استرح.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for seq_index in range(20):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print(\"-\")\n",
        "    print(\"Input sentence:\", input_texts[seq_index])\n",
        "    print(\"Decoded sentence:\", decoded_sentence)\n",
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "lstm_seq2seq",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}